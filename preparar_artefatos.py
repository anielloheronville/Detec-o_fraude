# -*- coding: utf-8 -*-
"""preparar_artefatos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WjHvON2YoGl6ISGhTI0VSM827moqS4ow
"""

import pandas as pd
import joblib
import pickle
from sklearn.preprocessing import StandardScaler
from lightgbm import LGBMClassifier

# --- Etapa A: Carregamento dos Dados ---
filepath = '/content/drive/MyDrive/Projetos/creditcard.csv'
print(f"Carregando dados de '{filepath}'...")

try:
    # Apenas precisamos especificar o delimitador correto: a vírgula.
    df = pd.read_csv(filepath, delimiter=',')
    print("Dataset carregado com sucesso!")
except Exception as e:
    print(f"Erro ao carregar o arquivo: {e}")
    exit()

# Verificação de segurança para valores nulos
if df.isnull().values.any():
    print("Aviso: Valores nulos encontrados. Removendo linhas com dados ausentes.")
    df.dropna(inplace=True)

# --- Etapa B: Preparação dos Dados ---
print("Preparando os dados para o treinamento...")
scaler = StandardScaler()
df['scaled_Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))

X = df.drop(['Time', 'Amount', 'Class'], axis=1)
y = df['Class']

# --- Etapa C: Treinamento do Modelo ---
print("Treinando o modelo final...")
final_model = LGBMClassifier(
    n_estimators=100,
    num_leaves=31,
    max_depth=-1,
    learning_rate=0.1,
    random_state=42
)
final_model.fit(X, y)

# --- Etapa D: Salvando os Artefatos ---
print("\nSalvando Artefatos para o Dashboard...")
joblib.dump(scaler, 'scaler.joblib')
print("Scaler salvo como 'scaler.joblib'")

joblib.dump(final_model, 'best_fraud_detection_model.joblib')
print("Modelo salvo como 'best_fraud_detection_model.joblib'")

with open('best_fraud_detection_model.pkl', 'wb') as file:
    pickle.dump(final_model, file)
print("Modelo salvo também como 'best_fraud_detection_model.pkl'")

print("\nArtefatos prontos!")