# -*- coding: utf-8 -*-
"""Detecção de Fraude.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ru1ViKiibNofPzBX4DnziuHR1yKRx-mb
"""

# -*- coding: utf-8 -*-
"""
Script Avançado para Evolução e Deploy do Modelo de Detecção de Fraude
"""

# 1. Importação das bibliotecas necessárias
import pandas as pd
import numpy as np
import joblib # Para salvar o modelo no formato .joblib
import pickle # Para salvar o modelo no formato .pkl
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, roc_auc_score

# --- Etapa A: Carregamento e Limpeza dos Dados (Função Reutilizável) ---

def load_and_clean_data(filepath):
    """Carrega, limpa e prepara o dataset de fraude."""
    print("Iniciando carregamento e limpeza dos dados...")
    try:
        # Changed delimiter from ';' to ','
        df = pd.read_csv('/content/drive/MyDrive/Projetos/creditcard.csv', delimiter=',', dtype=str)
    except FileNotFoundError:
        print(f"Erro: O arquivo '{filepath}' não foi encontrado.")
        return None

    def clean_number_string(s):
        if isinstance(s, str):
            s = s.replace('.', '').replace(',', '.')
        return s

    for col in df.columns:
        if col != 'Class':
            df[col] = df[col].apply(clean_number_string)

    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    df.dropna(inplace=True)
    df['Class'] = df['Class'].astype(int)

    print(f"Dataset limpo e pronto, com {df.shape[0]} linhas.")
    return df

# Executar a limpeza
df = load_and_clean_data('creditcard_reduzido.csv')
if df is None:
    exit()

# --- Etapa B: Preparação dos Dados ---

print("\nPreparando os dados para o treinamento...")
scaler = StandardScaler()
df['scaled_Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))

# LINHA A SER ADICIONADA:
joblib.dump(scaler, 'scaler.joblib')
print("Scaler salvo com sucesso como 'scaler.joblib'")

X = df.drop(['Time', 'Amount', 'Class'], axis=1)
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)


# --- Etapa C: Treinamento e Avaliação de Múltiplos Modelos ---

# 1. Modelo Baseline: RandomForest (do exercício anterior)
print("\n--- Treinando Modelo 1: RandomForest (Baseline) ---")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight="balanced", n_jobs=-1)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
print("Avaliação RandomForest:")
print(classification_report(y_test, y_pred_rf, target_names=['Não Fraude (0)', 'Fraude (1)']))
print(f"AUC-ROC RandomForest: {roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]):.4f}")

# 2. Novo Modelo: LightGBM (Default)
print("\n--- Treinando Modelo 2: LightGBM (Default) ---")
lgbm_model = LGBMClassifier(random_state=42)
lgbm_model.fit(X_train, y_train)
y_pred_lgbm = lgbm_model.predict(X_test)
print("Avaliação LightGBM (Default):")
print(classification_report(y_test, y_pred_lgbm, target_names=['Não Fraude (0)', 'Fraude (1)']))
print(f"AUC-ROC LightGBM (Default): {roc_auc_score(y_test, lgbm_model.predict_proba(X_test)[:, 1]):.4f}")


# --- Etapa D: Otimização de Hiperparâmetros para o LightGBM ---

print("\n--- Otimizando o Modelo LightGBM com RandomizedSearchCV ---")
param_dist = {
    'n_estimators': [100, 200, 500],
    'learning_rate': [0.01, 0.05, 0.1],
    'num_leaves': [31, 50, 100],
    'max_depth': [-1, 10, 20]
}
random_search = RandomizedSearchCV(
    LGBMClassifier(random_state=42),
    param_distributions=param_dist,
    n_iter=10,
    cv=3,
    scoring='roc_auc',
    random_state=42,
    n_jobs=-1
)
random_search.fit(X_train, y_train)

best_lgbm = random_search.best_estimator_

print("\nMelhores parâmetros encontrados:", random_search.best_params_)

print("\n--- Avaliação do Modelo 3: LightGBM (Otimizado) ---")
y_pred_best_lgbm = best_lgbm.predict(X_test)
print("Avaliação LightGBM (Otimizado):")
print(classification_report(y_test, y_pred_best_lgbm, target_names=['Não Fraude (0)', 'Fraude (1)']))
print(f"AUC-ROC LightGBM (Otimizado): {roc_auc_score(y_test, best_lgbm.predict_proba(X_test)[:, 1]):.4f}")


# --- Etapa E: Deploy do Melhor Modelo (Salvando em Joblib e Pickle) ---

print("\n--- Etapa de Deploy: Salvando o Melhor Modelo em Múltiplos Formatos ---")
# O melhor modelo é o LightGBM Otimizado
final_model_to_save = best_lgbm

# 1. Salvar o modelo com Joblib (bom para objetos com grandes arrays numpy)
model_filename_joblib = 'best_fraud_detection_model.joblib'
joblib.dump(final_model_to_save, model_filename_joblib)
print(f"Modelo salvo com sucesso como '{model_filename_joblib}'")

# 2. Salvar o modelo com Pickle (biblioteca padrão do Python)
model_filename_pickle = 'best_fraud_detection_model.pkl'
with open(model_filename_pickle, 'wb') as file:
    pickle.dump(final_model_to_save, file)
print(f"Modelo salvo com sucesso também como '{model_filename_pickle}'")


# --- Etapa F: Simulação de Uso do Modelo Salvo ---

# Carregar o modelo do arquivo (usaremos o joblib para o exemplo, mas o pickle funcionaria igual)
loaded_model = joblib.load(model_filename_joblib)
print(f"\nModelo '{model_filename_joblib}' carregado com sucesso para simulação.")

def predict_single_transaction(transaction_data, model, scaler):
    """
    Simula a previsão para uma única nova transação.
    'transaction_data' deve ser um dicionário com as mesmas colunas de X.
    """
    transaction_df = pd.DataFrame([transaction_data])
    transaction_df['scaled_Amount'] = scaler.transform(transaction_df[['Amount']].values)
    transaction_df = transaction_df.drop(['Amount'], axis=1)
    transaction_df = transaction_df[X_train.columns]

    prediction = model.predict(transaction_df)[0]
    probability = model.predict_proba(transaction_df)[0][1]

    return "Fraude" if prediction == 1 else "Não Fraude", probability

# Simular uma nova transação (usando a primeira linha dos dados de teste como exemplo)
sample_transaction_data = df.drop(['Time', 'Class', 'scaled_Amount'], axis=1).iloc[0].to_dict()

print("\n--- Testando a Previsão em uma Nova Transação ---")
print("Dados da transação de exemplo:", sample_transaction_data)
prediction_result, fraud_probability = predict_single_transaction(sample_transaction_data, loaded_model, scaler)

print(f"\nResultado da Previsão: {prediction_result}")
print(f"Probabilidade de ser Fraude: {fraud_probability:.2%}")

print("\nProcesso de evolução do projeto concluído!")